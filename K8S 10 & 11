==> EKS- Elastic Kubenetes Service
--------------------------------------
           It is managed by the aws providers so its managed K8s cluster. 
*Controlpane (master) completely managed by AWS. 
* EKS is the best place to run k8s applications bcoz of its security, reliability and scalability. 
* EKS can be integrated with manay other AWS services such as ELB, Amazon CloudWatch, AutoScaling Group, IAM, VPC, Providing you a seamless experiance to monitor, laod balance your 
application. 
* make it easy for us to K8s on AWS without needing to install, operate and manitain your own k8s control plane. 

=> Managed control plane: AWS EKS provides a scalable and high available control plane that runs across multiple AWS availability zones. Ths aws eks service automatocally manages 
the scalability and availability of the k8s API servers and etcd persistence layer of each cluster. AWS EKS runs the k8s cotrol plane across 3 availabilirty zones in order to ensure 
high availability and it detects  and replaces unhealthy masters. 

-> Diff ways to set up EKS cluster: 
1) AWS managed console
2) Terraform
3) eksctl utility provided by AWS

==> Step by Step procedure using AWS console:
    -----------------------------------------
1) Create a IAM (Identity and access management)Role for EKS Cluster. - we should have admin/permissions to crete a role. 
       EKS-Cluster

IAM Dashboard - Roles - create Role - AWS service- Choose a use case - EKS - EKS Cluster (i am giving a permission to IAM role to manage EKS)- Name - create a Role. 

2) Create a dedicated VPC for EKS Cluster. using Cloud Formation. https://amazon-eks.s3.us.west-2.amazonaws.com/cloudformation/2020-04-21/amazon-eks-vpc-private-subnets.yaml
2) Now use "Default VPC"
3) Create a Cluster:           

EKS - Clssters- Create Cluster - Name: EKS Demo - Kubenetes Version: 1.26 (should not use latest verison it may have some errors/defects. so we use old versions)
- Cluster Version Role: EKS_Cluster_Role - Tags - Next - 

VPC - Default one
Security Group: Default  (If we have VPC then we have to selecet that one)
Cluster End Point Access: 
   1) Public- The end point is accessible from outside the k8s cluster, usually over the internet.it allaows external users or services to communicate with the end point. 
   2) Private and Public - Selet this one (its end point can be accessible inside and ouside the cluster. it provides flexiblility for communication btw external and internal service)
   3) Private - In rela time we use this. When i dont want that kubectl command executed from internet. i mean diff network servers. accessing an end point within thek8s 
cluster itself. 
Network Add-ons: we use Weave Network while instaling K8s in server. so like that aws has its own network. it selected by default - Next
Configure observability- control plane logging- leave them as deselected. dont select any one bcoz chargable ones- Next and crete a cluster. 


4) Create a Server to connect: 
     we have control plae but we need CLI to connect and we need kubeconfig file to connect with control plane. Now we create a server (client m/c to install the kubectl) from
i can communicate with. 

Now we can see in google also- Install kubectl|Kubenetes - Install and Set Up kubectl on Linux - Install kubectl binary with curl on Linux
 -> curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

[ec2-user@ip-172-31-47-63 ~]$ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   138  100   138    0     0    432      0 --:--:-- --:--:-- --:--:--   433
100 47.5M  100 47.5M    0     0  63.3M      0 --:--:-- --:--:-- --:--:-- 63.3M

-> Install kubectl - sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

[ec2-user@ip-172-31-47-63 ~]$ sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
[ec2-user@ip-172-31-47-63 ~]$ kubectl version --client
Client Version: v1.28.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3

No we can see the version of that client. but we cant see any kubeconfig file inside. without config file we cant connect. 

[ec2-user@ip-172-31-47-63 ~]$ ls ~/.
kubectl
[ec2-user@ip-172-31-47-63 ~]$ ls -lar  ~/.
total 48720
drwx------. 2 ec2-user ec2-user       29 Nov 14 13:26 .ssh
-rw-r--r--. 1 ec2-user ec2-user 49872896 Nov 14 13:39 kubectl
-rw-r--r--. 1 ec2-user ec2-user      492 Nov 24  2022 .bashrc
-rw-r--r--. 1 ec2-user ec2-user      141 Nov 24  2022 .bash_profile
-rw-r--r--. 1 ec2-user ec2-user       18 Nov 24  2022 .bash_logout
-rw-------. 1 ec2-user ec2-user      215 Nov 14 14:26 .bash_history
drwxr-xr-x. 3 root     root           22 Nov 14 13:26 ..
drwx------. 3 ec2-user ec2-user      110 Nov 14 14:26 .

Now install AWS CLI- Serach in google - installation of aws cli - version 2

curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
sudo yum install unzip -y
unzip awscliv2.zip     
sudo ./aws/install


We have installed cli but still need credentials connect with 
[ec2-user@ip-172-31-47-63 ~]$ aws eks list-clusters

Unable to locate credentials. You can configure credentials by running "aws configure".   --> It means we have to give credentials to conncet each other. 

Go to AWS account- Security credentials- Crete access key- note down that access key and Secret key, region (ap-south-1). 

[ec2-user@ip-172-31-47-63 ~]$ aws configure
AWS Access key ID[None]: AKIAXB6GHYM2Q43WMDF7
AWS Secret Access key: aksa9s73bmdjxmx6d
Defalut region: ap-south-1
Defalut output format: json

Now we have got that config file. now we want that kube config file. 

[ec2-user@ip-172-31-47-63 ~]$ aws eks kube-config --name eks_demo --region ap-south-1

[ec2-user@ip-172-31-47-63 ~]$ cat .kube/config 

Now we can see config file here. 

Then we have to create worker nodes. will crete these worker nodes in EKS worker node IAM Role. 

4) Create IAM role for EKS worker Nodes: Crete a new role with below policies. Select use case as EC2. 
  a. AmazonEKSWorkerNodePolicy
  b. AmzonEKS CNI Policy
  c. AmazonEC2ContainerRegistryReadOnly    --> here read only bcoz here the container will just pull the image. not push any image. 

Role name: EKS_worker_Role

5) Create Worker Nodes group: 
     Here we will create worker nodes group but not manaually. Node group in the background it is going to create Autoscaling group with launch configurations.
We can choose Nexus and docker hub instead of ECR. but these are not managed by AWS. in this case we need authenticate with username and password. 

Go to EKS cluster- cluster - EKS_Demo - configuration - compute- Add Node group -
Name: EKS_Node_group
Node IAM Role: EKS_Woker_Role  (Here we will select worker node role that we have just creted)
 
Next - 
AMI type: Amazon Linux2 (AL2_x86_64)    --> its default one. 
Capacity type: On-Demand      --> Recommended one
Instance Type: t2.micro   (This is the capacity of our worker nodes. in real time will select larger one)
Disk Size: 20GiB


















