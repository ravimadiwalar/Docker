In Real Time nobody wikl remember that load balancer IP. so we have to create a domain for that load balancer. 

we can do this domain in Route 53 in AWS. 53 is its port. here we have to mention our load balancer external IP. user can acccess it from that domain name directly. here we can 
access the data of the private subnet also via load balancer extrtnal IP.

Cluster AutoScaler: 
-------------------
        It will scale the servers. but POD autoscaler(HPA) will scale the pods. while creating the EKS cluster we have mentioned that MIn servers 2 and Max servers 5 in Node group. 

Now we have 2 min servers but if we terminate one node. whichever pods under that node will fit into other node which is running. but it will take 5 mins this is k8s work.
kubectl get pods -o wide

but aws will create one new node bcoz desired nodes mentioned is 2. when our servers are running out of resources then it will create one more node.

Now we have 2 nodes with 8 gb each. in application yml file we have mentioned resource as 1 gb. it means we can create 10-12 pods. 

lets do kubectl scale deployment <deployment name> --replicas 14

will get 10 pods running and 2 pods pending. pending bcoz each pod has reserved its 1 gb capacity and we have 16 gb max. so we dont have enough resources to give to new pod.
here we have to do either increse the capacity of servers or increase the nodes. we do scaling of nodes by ClusterAutscaler. 

This Cluster auto scaler will act as a bridge btw EKS cluser and AWS austoscaing group. 

This clusterAutoscaler is one application. this will talk to API server and get the details of the nodes. and it will make "AWS API calls" to adjust autoscalig group desired numbers.

First we have to create a clyster autoscaler yaml file and apply. then go to AWS and create one policy and name that to "clusterautoscaler" and attach that to node groups. then 
we will get nodes while increase the load and decrese when load is less automatically. 

Cluster Autoscaler typically runs as a Deployment in your cluster.

If we want to check the logs of the pods : kubectl logs <podName> -n kube-system


==> Ingress: 
-------------
      if we deploy any application with load balancer service we will get diff loda balancer IP's. Load Blancer port: 80 and 443. here we will create a single load balancer that
can have multiple applications/micro services. once we enter the port ingress will route that to entered application. 

Note: if we rae using custome k8s cluster (using minikube, kubeadm). in this case there is no Loadbalancer integarted. with this defalut set up you can only use NodePort.  

"K8s ingress is a resource to add rules for trafiic from external sources to the service in the k8s cluster ". 

==> K8s ingress: 
-----------------
  Its a native resource where you can have rules to route traffic from an external source to service end points residing inside the cluster. it requires an ingress controller 
for routing the rules specified in the ingress object. 

Ingress has 2 components: 
1) Ingress controler: (proxy service (web server)): All the external traffice will go to here first.

  Nginx ingress controllers
  haproxy
  Terafic
  consul
  istio -> its Service mesh. it has lot more features than other controllers.  
2) Ingress (Rules): it supports 
   a) Host based routing: 
   b) path based routing: 
These two routings are "layer 7"

external Load balancer -> Ingress controler -> Ingress (Rules)

Lets take one example from mithu git gub where we have all yaml files. so it would be easy to understand the process so. (Refer my github - kubernetes ingress- step step process)

Here we can deploy ingress as a daemonset or deployment. any one is fine. 


=> procedure: 

-First we will create a nginx ingress controller and then apply. 
-then create ingress resource and here we will mention the domain of the java web app and maven web app and service names that will connect to particular service while brwosing.
-we will create a load balancer for the ingress controller and attach this load balancer to the java and maven domains. and we have to mention the host name in ingress host and path 
  also in ingress resource as a path and service names. 
- if we browse from outside we will get the required oen. 















