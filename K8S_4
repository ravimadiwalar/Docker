  Deployment:
------------
its a recommended way to deploy a pod and RS is the internally it will deploy RS. we use this bcoz in RS and RC we cant update the version of the image we have. but in Deployment 
we can.

Benifits:
* Internally set a RS. it will mange the pods.
* It will set all pod specs.
*Roll back to older deployment version.
*Scale up and down
*pause and resuem the deployment
*Clean up the older RS that you dont need anymore.  


Ex:
consider mavenwebapprs and change the image version to 2 before it had latest. but after applying the kubectl we cant see any changes in the version (Image: dockerhandson/maven-web-app). 

ubuntu@ip-172-31-33-243:~$ kubectl apply -f mavenwebapprs.yml
replicaset.apps/mavenwebapprs configured
service/mavenwebappsvc unchanged
ubuntu@ip-172-31-33-243:~$ kubectl get pods
NAME                  READY   STATUS        RESTARTS   AGE
mavenwebapprs-hb6v7   0/1     Pending       0          34m
mavenwebapprs-hcnvm   1/1     Terminating   0          10h
mavenwebapprs-nz49f   1/1     Terminating   0          10h
mavenwebapprs-w4sjc   0/1     Pending       0          34m
nginxds-qpftp         1/1     Running       0          10h
ubuntu@ip-172-31-33-243:~$ kubectl describe pod mavenwebapprs-w4sjc
Name:           mavenwebapprs-w4sjc
Namespace:      default
Priority:       0
Node:           <none>
Labels:         app=mavenwebapp
Annotations:    <none>
Status:         Pending
IP:
IPs:            <none>
Controlled By:  ReplicaSet/mavenwebapprs
Containers:
  mavenwebappcontainer:
    Image:        dockerhandson/maven-web-app
    Port:         8080/TCP
    Host Port:    0/TCP
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5cnpt (ro)
Conditions:
  Type           Status
  PodScheduled   False
Volumes:
  default-token-5cnpt:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-5cnpt
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age                   From               Message
  ----     ------            ----                  ----               -------
  Warning  FailedScheduling  3m20s (x31 over 34m)  default-scheduler  0/2 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 1 node(s) had taint {node.kubernetes.io/unreachable: }, that the pod didn't tolerate.

Deployment startegies: These strategies will not applicable when we are craeting new pods. bcoz it will recrete new pods once old ones terminate/kill. 
------------------------
1) Recreate- When i am updating my deployment using Recrete strategy, all the old pods are killed all at once and get replaced all at once with new ones.
* here will face some downtime in deployment. why bcoz all will kill once and create once with new onec. so user will face some downtime issue.

strategy:
  type: Recreate

2)Rollung update(Default)- here will will not not face zero downtime deployment issue. whay bcoz a rolling update waits for new pods to become ready before it starts scaling 
down the old ones. if there is a problem , the rolling update or deployment can be aborted without bringing the whole clusterdown. in the YAML definition file for this type of
deployment, a new image replace the old image. 

strategy:
  type: RollingUpdate
  rollinUpdate:
    maxSurge: 1
    maxUnavailable: 1
    minReadSeconds: 30


Lets craete a recrete strategy: i have just update the required lines. 

ubuntu@ip-172-31-33-243:~$ cp javawebapprc.yml javawebappdeployment.yml
ubuntu@ip-172-31-33-243:~$ vi javawebappdeployment.yml
ubuntu@ip-172-31-33-243:~$ cat javawebappdeployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: javawebappdeployment
spec:
  replicas: 2     #internaly it will create RS
  selector:
     matchLabels:
       app: javawebapp
  strategy:
    type: Recreate   #This strategy will applicable whiel updating the version
  template:
    metadata:
      name: javawebapppod
      labels:
        app: javawebapp
    spec:
      containers:
      - name: javawebappcontainer
        image: dockerhandson/java-web-app:1
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: javawebappsvc
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080

ubuntu@ip-172-31-33-243:~$ kubectl apply -f javawebappdeployment.yml
deployment.apps/javawebappdeployment created
service/javawebappsvc created


*"watch kubectl get pods" --> it will be used to see the live pods craetion and termination in worker nodes while applyig the kubectl appy command. 

ubuntu@ip-172-31-33-243:~$ kubectl get svc
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
javawebappsvc   NodePort    10.102.134.133   <none>        80:32098/TCP   12m
kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP        25m


Now go and browse with svc nodeport. 

Now lets update the version to 4 and apply the ctl and browse we may face some downtime issue. after some time will get that application. 

ubuntu@ip-172-31-33-243:~$ kubectl get svc
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
javawebappsvc   NodePort    10.102.134.133   <none>        80:32098/TCP   26m
kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP        39m
ubuntu@ip-172-31-33-243:~$ kubectl get all
NAME                                        READY   STATUS    RESTARTS   AGE
pod/javawebappdeployment-6b6d59d84c-6fpxl   1/1     Running   0          3m56s
pod/javawebappdeployment-6b6d59d84c-j6rjq   1/1     Running   0          3m56s

NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service/javawebappsvc   NodePort    10.102.134.133   <none>        80:32098/TCP   29m
service/kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP        42m

NAME                                   READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/javawebappdeployment   2/2     2            2           29m

NAME                                              DESIRED   CURRENT   READY   AGE
replicaset.apps/javawebappdeployment-6b6d59d84c   2         2         2       3m56s
replicaset.apps/javawebappdeployment-7cb95f67b4   0         0         0       29m


* here we can see 2 RS.  - NAME                                              DESIRED   CURRENT   READY   AGE
                           replicaset.apps/javawebappdeployment-6b6d59d84c   2         2         2       3m56s
                          replicaset.apps/javawebappdeployment-7cb95f67b4   0         0         0       29m 


one we can see desired 2 and current 2. and other one is zero. bcoz this zero one is older version tahts why it is zero. 

#using "kubectl rollout status deployment <Deploymentname>" we can find out the status . 

ubuntu@ip-172-31-33-243:~$ kubectl rollout status deployment javawebappdeployment
deployment "javawebappdeployment" successfully rolled out

We can see the History also. How many revisions of the deployment ==> "kubectl rollout history deployment <Deploymentname>"

ubuntu@ip-172-31-33-243:~$ kubectl rollout history deployment javawebappdeployment
deployment.apps/javawebappdeployment
REVISION  CHANGE-CAUSE
1         <none>
2         <none>


To know what pod template has been used in both versions==>  kubectl rollout history deployment <deploymentName> --revision=1
                                                             kubectl rollout history deployment <deploymentName> --revision=1

ubuntu@ip-172-31-33-243:~$ kubectl rollout history deployment javawebappdeployment --revision=1
deployment.apps/javawebappdeployment with revision #1
Pod Template:
  Labels:       app=javawebapp
        pod-template-hash=7cb95f67b4
  Containers:
   javawebappcontainer:
    Image:      dockerhandson/java-web-app:1
    Port:       8080/TCP
    Host Port:  0/TCP
    Environment:        <none>
    Mounts:     <none>
  Volumes:      <none>

We can see the same version in "kubectl describe pod <podname>" to just check for confirmation. 

* If required we can rollback to required version. ==> "kubectl rollout undo deployment <deploymentname> --to-revision=1"

ubuntu@ip-172-31-33-243:~$ kubectl rollout undo deployment javawebappdeployment --to-revision=1
deployment.apps/javawebappdeployment rolled back

above we have mentioned the version we wanted. if we dont mention also it will consider the previous one by default. 

==> Rolling Strategy: 
----------------------
ubuntu@ip-172-31-33-243:~$ cp javawebappdeployment.yml javawebappdeployment_rolling.yml
ubuntu@ip-172-31-33-243:~$ vi javawebappdeployment_rolling.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: javawebappdeployment
spec:
  replicas: 2     #internaly it will create RS
  selector:
     matchLabels:
       app: javawebapp
  strategy:
    type: RollingUpdate   #This strategy will applicable whiel updating the version
    rollingUpdate:
      maxSurge: 1          #if we dont mention these also it will consider 1
      maxUnavailable: 1
  minReadySeconds: 30      #This is sibling of strategy and come in the same line of strategy
  template:
    metadata:
      name: javawebapppod
      labels:
        app: javawebapp
    spec:
      containers:
      - name: javawebappcontainer
        image: dockerhandson/java-web-app:4
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: javawebappsvc
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080



Above we have updated the rolling strategy: 
strategy:
    type: RollingUpdate   #This strategy will applicable whiel updating the version
    rollingUpdate:
      maxSurge: 1          #if we dont mention these also it will consider 1
      maxUnavailable: 1
  minReadySeconds: 30      #This is sibling of strategy and come in the same line of strategystrategy:
    type: RollingUpdate   #This strategy will applicable whiel updating the version
    rollingUpdate:
      maxSurge: 1          #if we dont mention these also it will consider 1
      maxUnavailable: 1
  minReadySeconds: 30      #This is sibling of strategy and come in the same line of strategy. the new version will take 30 sec to replace with old one. until it replaces the old 
                             one will run. zero downtime reployment. 



* what is the diff btw kubectl apply and kubectl craete? 
==> kubectl create will just craete the object. but kubectl apply will create and apply if object isn't exist also. 

buntu@ip-172-31-33-243:~$ ubuntu@ip-172-31-33-243:~$ kubectl rollout history deployment javawebappdeployment
deployment.apps/javawebappdeployment
REVISION  CHANGE-CAUSE
1         <none>


above we can see Change cause is none (it means what cause for this change). if we want to see that change cause use 
==> "kubectl apply -f javawebappdeployment_rolling.yml --record=true"


in CHANGE-CAUSE column we can see "kubectl apply -f javawebappdeployment_rolling.yml"

Here also we can change the version and check the using watch command and we cant face any downtime issue. all othere commands we can apply here also as same as Recrete. 

Blue/Green Deployment: (Red/Black deployment)
----------------------------------------------
in Blue/Green Deployment strategy the old version of the application (green) and new version (blue) get deployed at the same time. when both of these are deployed, user only 
have access to the green; whereas, the blue is avaliable to your QA team for test automation on seperate service or via direct port-forwarding. 

After the new version has been tested and is signed off for release., the service is switched to the blue version with the old green version being scaled down. 

here will not update the object with new version. instaed will crete onle more deployment with diff labels. QA team will test that new depoyment and once they approve we have to 
switch this with old version. to do that fisrt we need to understand that user request goes to serviec and that servoce will reroute to pods/appication using load balancer. 

Now to achieve this we have to change the selectors in sevice as same as new deployment. now it has compltely swaitched to new deployment and we can delete the old deployment. 
It will consume more memory and cpu. bcoz sometimes it runs under bith deployment. 

EX: it will be used in flipkart, uber, amazon etc --> they always add new features and then deploy new one which was certified by QA team. so they dont face any downtime issue.
   some time they use rolling Update also. but in Rolling Update we have some issues. if our application  not throughly automated tested end uses will face the issues.  


* Deployment is the recommended way of deployment fo pods.
* Agent software is daemon Set. if we want some softwares part of your eavery node. we use DaemonSet object. 


EX:

apiversion: apps/v1
kind: Deployment
metadata:
  name: springappdeployment
spec: 
  replicas: 2
  selector: 
    matchlabels:
      app: springapp           # here if we dont mention also it will consider the RollingUpdate as default or if we want we can also
  template: 
    metadata:
      name: springapppod
      labels:
        app: springapp
    spec:
    containers:
    - image: dockerhandson/spring-boot-mango:1 
      name: springappcontainer
      ports: 
      - containerPort: 8080
      env: 
      - name: MONGO_DB_HOSTNAME
        value: mango
      - name: MONGO_DB_USERNAME
        value: devdb
      - name: MONGO_DB_PASSOWRD
        value: devdb@123
---
apiVersion: v1
kind: Service
metadata:
  name: springappsvc
spec:
  type: NodePort       #we can convert from cluster to nodeport but not from nodeport to cluster
  selector:
    app: springapp
  ports: 
  - port: 80
    targetPort: 8080
---
apiVersion: v1
kind: ReplicationController
metadata: 
  name: mongorc
spec: 
  selector: 
    app: mongo
  template:
    metadata: 
      name: mongopod
      labels:
         app: mongo
    spec: 
      containers:
      - name: mongocontainer
        image: mongo
        ports:
        - containerPort: 27017















