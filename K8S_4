Deployment:
------------
its a recommended way to deploy a pod and internally it will deploy RS. we use this bcoz in RS and RC we cant update the version of the image we have. but in Deployment 
we can.

Benifits:
* Internally set a RS. it will manage the pods.
* It will set all pod specs.
*Roll back to older deployment version.
*Scale up and down
*pause and resuem the deployment
*Clean up the older RS that you dont need anymore.  

==> Doff btw pod and Deployemnt?
Deployment has AutoHealing and Auto Scaling behaviour. but POD dosen't. will get Zero downtime issue. what deloyment will do that end of the process will create a POD only 
using ReplicaSet (controller of pods). but K8s recommended one to deploya pod is Deployment. 

Ex:
consider mavenwebapprs and change the image version to 2 before it had latest. but after applying the kubectl we cant see any changes in the version (Image: dockerhandson/maven-web-app). 
and we can see the old pods. we cant see any new pods(check the AGE of the pod creation).

ubuntu@ip-172-31-33-243:~$ kubectl apply -f mavenwebapprs.yml
replicaset.apps/mavenwebapprs configured
service/mavenwebappsvc unchanged
ubuntu@ip-172-31-33-243:~$ kubectl get pods
NAME                  READY   STATUS        RESTARTS   AGE
mavenwebapprs-hb6v7   0/1     Pending       0          34m
mavenwebapprs-hcnvm   1/1     Terminating   0          10h
mavenwebapprs-nz49f   1/1     Terminating   0          10h
mavenwebapprs-w4sjc   0/1     Pending       0          34m
nginxds-qpftp         1/1     Running       0          10h
ubuntu@ip-172-31-33-243:~$ kubectl describe pod mavenwebapprs-w4sjc
Name:           mavenwebapprs-w4sjc
Namespace:      default
Priority:       0
Node:           <none>
Labels:         app=mavenwebapp
Annotations:    <none>
Status:         Pending
IP:
IPs:            <none>
Controlled By:  ReplicaSet/mavenwebapprs
Containers:
  mavenwebappcontainer:
    Image:        dockerhandson/maven-web-app
    Port:         8080/TCP
    Host Port:    0/TCP
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5cnpt (ro)
Conditions:
  Type           Status
  PodScheduled   False
Volumes:
  default-token-5cnpt:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-5cnpt
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age                   From               Message
  ----     ------            ----                  ----               -------
  Warning  FailedScheduling  3m20s (x31 over 34m)  default-scheduler  0/2 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 1 node(s) had taint {node.kubernetes.io/unreachable: }, that the pod didn't tolerate.

Deployment startegies: These strategies will not applicable when we are craeting new pods. these will be applicable once we are updating the version of the image. 
------------------------
1) Recreate- When i am updating my deployment using Recrete strategy, all the old pods are killed all at once and get replaced all at once with new ones.
* here will face some downtime in deployment. why bcoz all will kill once and create once with new onec. so user will face some downtime issue.

strategy:
  type: Recreate

2)Rolling update(Default)- here will see zero downtime deployment issue. whay bcoz a rolling update waits for new pods to become ready before it starts scaling 
down the old ones. if there is a problem , the rolling update or deployment can be aborted without bringing the whole clusterdown. in the YAML definition file for this type of
deployment, a new image replace the old image. 

strategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 1
    maxUnavailable: 1
    minReadySeconds: 30


Lets craete a recrete strategy: i have just update the required lines. 

ubuntu@ip-172-31-33-243:~$ cp javawebapprc.yml javawebappdeployment.yml
ubuntu@ip-172-31-33-243:~$ vi javawebappdeployment.yml
ubuntu@ip-172-31-33-243:~$ cat javawebappdeployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: javawebappdeployment
spec:
  replicas: 2     #internaly it will create RS
  selector:
     matchLabels:
       app: javawebapp
  strategy:
    type: Recreate   #This strategy will applicable while updating the version
  template:
    metadata:
      name: javawebapppod
      labels:
        app: javawebapp
    spec:
      containers:
      - name: javawebappcontainer
        image: dockerhandson/java-web-app:1
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: javawebappsvc
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080

ubuntu@ip-172-31-33-243:~$ kubectl apply -f javawebappdeployment.yml
deployment.apps/javawebappdeployment created
service/javawebappsvc created


*"watch kubectl get pods" --> it will be used to see the live pods craetion and termination in worker nodes while applyig the kubectl appy command. 

ubuntu@ip-172-31-33-243:~$ kubectl get svc
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
javawebappsvc   NodePort    10.102.134.133   <none>        80:32098/TCP   12m
kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP        25m


Now go and browse with svc nodeport. 

Now lets update the version to 4 and apply the ctl and browse we may face some downtime issue. after some time will get that application. 

ubuntu@ip-172-31-33-243:~$ kubectl get svc
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
javawebappsvc   NodePort    10.102.134.133   <none>        80:32098/TCP   26m
kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP        39m
ubuntu@ip-172-31-33-243:~$ kubectl get all
NAME                                        READY   STATUS    RESTARTS   AGE
pod/javawebappdeployment-6b6d59d84c-6fpxl   1/1     Running   0          3m56s
pod/javawebappdeployment-6b6d59d84c-j6rjq   1/1     Running   0          3m56s

NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service/javawebappsvc   NodePort    10.102.134.133   <none>        80:32098/TCP   29m
service/kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP        42m

NAME                                   READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/javawebappdeployment   2/2     2            2           29m

NAME                                              DESIRED   CURRENT   READY   AGE
replicaset.apps/javawebappdeployment-6b6d59d84c   2         2         2       3m56s
replicaset.apps/javawebappdeployment-7cb95f67b4   0         0         0       29m


* here we can see 2 RS.  - NAME                                              DESIRED   CURRENT   READY   AGE
                           replicaset.apps/javawebappdeployment-6b6d59d84c   2         2         2       3m56s
                          replicaset.apps/javawebappdeployment-7cb95f67b4   0         0         0       29m 


one we can see desired 2 and current 2. and other one is zero. bcoz this zero one is older version thats why it is zero. 

#using "kubectl rollout status deployment <Deploymentname>" we can find out the status .

ubuntu@ip-172-31-33-243:~$ kubectl rollout status deployment javawebappdeployment
deployment "javawebappdeployment" successfully rolled out                                # it means the updated version has been successfully updated. 

We can see the History also. How many revisions of the deployment ==> "kubectl rollout history deployment <Deploymentname>"

ubuntu@ip-172-31-33-243:~$ kubectl rollout history deployment javawebappdeployment
deployment.apps/javawebappdeployment
REVISION  CHANGE-CAUSE
1         <none>
2         <none>

here we can see that now we have update only 2 version. version 1 and 2. if we have 4 it will show 4. 
To know what pod template has been used in both versions==>  kubectl rollout history deployment <deploymentName> --revision=1
                                                             kubectl rollout history deployment <deploymentName> --revision=2

here will see the version of the image that we used. 

ubuntu@ip-172-31-33-243:~$ kubectl rollout history deployment javawebappdeployment --revision=1
deployment.apps/javawebappdeployment with revision #1
Pod Template:
  Labels:       app=javawebapp
        pod-template-hash=7cb95f67b4
  Containers:
   javawebappcontainer:
    Image:      dockerhandson/java-web-app:1
    Port:       8080/TCP
    Host Port:  0/TCP
    Environment:        <none>
    Mounts:     <none>
  Volumes:      <none>

We can see the same version in "kubectl describe pod <podname>" to just check for confirmation. 

* If required we can rollback to required version. ==> "kubectl rollout undo deployment <deploymentname> --to-revision=1"

ubuntu@ip-172-31-33-243:~$ kubectl rollout undo deployment javawebappdeployment --to-revision=1
deployment.apps/javawebappdeployment rolled back

above we have mentioned the version we wanted. if we dont mention also it will consider the previous one by default -  "kubectl rollout undo deployment <deploymentname>"

==> Rolling Strategy: 
----------------------
ubuntu@ip-172-31-33-243:~$ cp javawebappdeployment.yml javawebappdeployment_rolling.yml
ubuntu@ip-172-31-33-243:~$ vi javawebappdeployment_rolling.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: javawebappdeployment
spec:
  replicas: 2     #internaly it will create RS
  selector:
     matchLabels:
       app: javawebapp
  strategy:
    type: RollingUpdate   #This strategy will applicable whiel updating the version
    rollingUpdate:
      maxSurge: 1          #if we dont mention these also it will consider 1
      maxUnavailable: 1
  minReadySeconds: 30      #This is sibling of strategy and come in the same line of strategy
  template:
    metadata:
      name: javawebapppod
      labels:
        app: javawebapp
    spec:
      containers:
      - name: javawebappcontainer
        image: dockerhandson/java-web-app:4
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: javawebappsvc
spec:
  type: NodePort
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080



Above we have updated the rolling strategy: 
strategy:
  type: RollingUpdate   #This strategy will applicable whiel updating the version
    rollingUpdate:
      maxSurge: 1          #if we dont mention these also it will consider 1
      maxUnavailable: 1
uminReadySeconds: 30      #This is sibling of strategy and come in the same line of strategy. the new version will take 30 sec to replace with old one. until it replaces the old 
                             one will run. zero downtime reployment. 



* what is the diff btw kubectl apply and kubectl craete? 
==> kubectl create will just craete the object. but kubectl apply will create and apply if object isn't exist also. 

ubuntu@ip-172-31-33-243:~$ ubuntu@ip-172-31-33-243:~$ kubectl rollout history deployment javawebappdeployment
deployment.apps/javawebappdeployment
REVISION  CHANGE-CAUSE
1         <none>


above we can see Change cause is none (it means what cause for this change). if we want to see that change cause use 
==> "kubectl apply -f javawebappdeployment_rolling.yml --record=true"


in CHANGE-CAUSE column we can see "kubectl apply -f javawebappdeployment_rolling.yml"

Here also we can change the version and check the using watch command and we cant face any downtime issue. all othere commands we can apply here also as same as Recrete. 

Blue/Green Deployment: (Red/Black deployment)
----------------------------------------------
in Blue/Green Deployment strategy the old version of the application (green) and new version (blue) get deployed at the same time. when both of these are deployed, user only 
have access to the green; whereas, the blue is avaliable to your QA team for test automation on seperate service or via direct port-forwarding. 

After the new version has been tested and is signed off for release., the service is switched to the blue version with the old green version being scaled down. 

here will not update the object with new version. instaed will crete one more deployment with diff labels. QA team will test that new depoyment and once they approve we have to 
switch this with old version. to do that fisrt we need to understand that user request goes to serviec and that servoce will reroute to pods/appication using load balancer. 

Now to achieve this we have to change the selectors in sevice as same as new deployment. now it has compltely swaitched to new deployment and we can delete the old deployment. 
It will consume more memory and cpu. bcoz sometimes it runs under both deployment. 

EX: it will be used in flipkart, uber, amazon etc --> they always add new features and then deploy new one which was certified by QA team. so they dont face any downtime issue.
   some time they use rolling Update also. but in Rolling Update we have some issues. if our application  not throughly automated tested end uses will face the issues.  


* Deployment is the recommended way of deployment fo pods.
* Agent software is daemon Set. if we want some softwares part of your every node. we use DaemonSet object. 


EX: to database add

apiVersion: apps/v1
kind: Deployment
metadata:
  name: springappdeployment
spec: 
  replicas: 2
  selector: 
    matchLabels:
      app: springapp           # here if we dont mention also it will consider the RollingUpdate as default or if we want we can also
  template: 
    metadata:
      name: springapppod
      labels:
        app: springapp
    spec:
      containers:
      - image: dockerhandson/spring-boot-mango:1 
        name: springappcontainer
        ports: 
        - containerPort: 8080
        env: 
        - name: MONGO_DB_HOSTNAME
          value: mango
        - name: MONGO_DB_USERNAME
          value: devdb
        - name: MONGO_DB_PASSOWRD
          value: devdb@123
---
apiVersion: v1
kind: Service
metadata:
  name: springappsvc
spec:
  type: NodePort       #we can convert from cluster to nodeport but not from nodeport to cluster
  selector:
    app: springapp
  ports: 
  - port: 80
    targetPort: 8080
---
apiVersion: v1
kind: ReplicationController
metadata: 
  name: mongorc
spec: 
  selector: 
    app: mongo
  template:
    metadata: 
      name: mongopod
      labels:
         app: mongo
    spec: 
      containers:
      - name: mongocontainer
        image: mongo
        ports:
        - containerPort: 27017
        env: 
        - name: MONGO_INITDB_ROOT_USERNAME
          value: devdb                               # This always match with springboot value
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: devdb@123                            # This always match with springboot value
---
apiVersion: v1
kind: Service
metadata: 
  name: mongo      #This always match with MONGO_DB_HOSTNAME. why bcoz spring app will talk to mongo database. 
spec: 
  type: ClusterIP
  selector: 
    app: mongo 
  ports: 
  - port: 27017                   #Why not 80. the hardcode is 27017 in developer file. it will route the traffic to 27017 port.
    targetPort: 27017

* To delete everything--> kubectl delete all --all 

ubuntu@ip-172-31-33-243:~$ kubectl apply -f springapp.yml
deployment.apps/springappdeployment created
service/springappsvc created
replicationcontroller/mongorc created
service/mongo created
ubuntu@ip-172-31-33-243:~$ kubectl get all
NAME                                       READY   STATUS              RESTARTS   AGE
pod/mongorc-6lrlx                          0/1     ContainerCreating   0          3s
pod/springappdeployment-5cfd644db9-b5xrp   0/1     ContainerCreating   0          3s
pod/springappdeployment-5cfd644db9-tnbw6   0/1     ErrImagePull        0          3s

NAME                            DESIRED   CURRENT   READY   AGE
replicationcontroller/mongorc   1         1         0       4s

NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service/kubernetes     ClusterIP   10.96.0.1        <none>        443/TCP        18m
service/mongo          ClusterIP   10.105.165.115   <none>        27017/TCP      4s
service/springappsvc   NodePort    10.97.159.236    <none>        80:31731/TCP   4s

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/springappdeployment   0/2     2            0           4s

NAME                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/springappdeployment-5cfd644db9   2         2         0       4s


Now go and browse with publicIP:31731. 

To check the logs: kubectl logs <podname>

If we want to execute the commands: kubectl exec <podname> ls /data/db
Now the data is part of inside the POD that conatiner file system. 

Now i am not using any volume concepts. so whatever we enter/store the application will not store. once pod get deleted the data will also get vanished. 

To find all the pods in all namespaces: kubectl get pods --all-namespaces

ubuntu@ip-172-31-33-243:~$ kubectl get pods --all-namespaces
NAMESPACE     NAME                                       READY   STATUS             RESTARTS   AGE
default       mongorc-6lrlx                              1/1     Running            0          22m
default       springappdeployment-5cfd644db9-b5xrp       0/1     ImagePullBackOff   0          22m
default       springappdeployment-5cfd644db9-tnbw6       0/1     ImagePullBackOff   0          22m
kube-system   coredns-74ff55c5b-9jmdj                    1/1     Running            12         27d
kube-system   coredns-74ff55c5b-j9ktx                    1/1     Running            12         27d
kube-system   etcd-ip-172-31-33-243                      1/1     Running            12         27d
kube-system   kube-apiserver-ip-172-31-33-243            1/1     Running            12         27d
kube-system   kube-controller-manager-ip-172-31-33-243   1/1     Running            12         27d
kube-system   kube-proxy-gnw5j                           1/1     Running            6          17d
kube-system   kube-proxy-zfxrk                           1/1     Running            12         27d
kube-system   kube-scheduler-ip-172-31-33-243            1/1     Running            12         27d
kube-system   weave-net-bkldg                            2/2     Running            26         27d
kube-system   weave-net-flzl2                            2/2     Running            13         17d





IMP
-----
* the labels will come under metadata only while creating a pod (tepmplate). but for  others labels will come under spec. 

* How do you list out all the resources that are availbel in particular namespaces?
kubectl get all
kubectl get all -A  --> it will display eveything with all namespaces.








