K8s Volume: 
-----------
It is used to store the data what we have in the application container. A container file system lives as long as the container does. so wen a container terminates and restart, 
filesystem changes are lost. Volumes in K8s are very easy to manage. its basically a directory that get mounted to a pod. after telling the container to use volumes for storing 
evergreen information, you can safely modify the pods without ever losing your data. 

K8s supports many types of volumes. Pod can use many volumes to single pod.

it supports lot of volumes
1) EmptyDir       --> its like a tmp dir. the data exist as long as the pod exists. if pod is deleted the data also get deleted. we will not lose the data if the conatiner deletes.
2) hostpath      --> Wherever our pod getting scheduled in that node/server we can attached server/host storage. 
3) nfs
4) awsElasticBlockstore
5) googlePersistantDisk
6) azureFile
7) azureDisk
8) ConfigMap
9) GitRepo(deprecated)
10)secret


There are concepts: 
1) persistentVolumes
2) persistentVolumeClaims


Example for hostPath: Now we have springapp.yml file as a stateless application. if we attache the volume it will get converted into stateful set app. 

apiVersion: apps/v1
kind: Deployment
metadata:
  name: springappdeployment
spec: 
  replicas: 2
  selector: 
    matchLabels:
      app: springapp           # here if we dont mention also it will consider the RollingUpdate as default or if we want we can also
  template: 
    metadata:
      name: springapppod
      labels:
        app: springapp
    spec:
      containers:
      - image: dockerhandson/spring-boot-mango:1 
        name: springappcontainer
        ports: 
        - containerPort: 8080
        env: 
        - name: MONGO_DB_HOSTNAME
          value: mango
        - name: MONGO_DB_USERNAME
          value: devdb
        - name: MONGO_DB_PASSOWRD
          value: devdb@123
---
apiVersion: v1
kind: Service
metadata:
  name: springappsvc
spec:
  type: NodePort       #we can convert from cluster to nodeport but not from nodeport to cluster
  selector:
    app: springapp
  ports: 
  - port: 80
    targetPort: 8080
---
apiVersion: v1
kind: ReplicationController
metadata: 
  name: mongorc
spec: 
  selector: 
    app: mongo
  template:
    metadata: 
      name: mongopod
      labels:
         app: mongo
    spec: 
      containers:
      - name: mongocontainer
        image: mongo
        ports:
        - containerPort: 27017
        env: 
        - name: MONGO_INITDB_ROOT_USERNAME
          value: devdb                               # This always match with springboot value
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: devdb@123                            # This always match with springboot value
        volumeMounts: 
        - name: mongovol                          #this name always match with volume name
          mountPath: "/data/db"    
     volumes:                                    #volume is the sibling of container. 
     - name: mongovol
       hostPath:              # mention the path type
         path: "/tmp/mongo"    #server dir where we store the data of container /data/db   
---
apiVersion: v1
kind: Service
metadata: 
  name: mongo      #This always match with MONGO_DB_HOSTNAME. why bcoz spring app will talk to mongo database. 
spec: 
  type: ClusterIP
  selector: 
    app: mongo 
  ports: 
  - port: 27017                   #Why not 80. the hardcode is 27017 in developer file. it will route the traffic to 27017 port.
    targetPort: 27017



* if any changes happens in our RC/RS, our pods will not recreted. we need to delete and create again. Now i deleted and updated new volume and apply. 

ubuntu@ip-172-31-33-243:~$ kubectl apply -f springapp.yml
deployment.apps/springappdeployment created
service/springappsvc created
replicationcontroller/mongorc created
service/mongo created
ubuntu@ip-172-31-33-243:~$ kubectl get pods
NAME                                   READY   STATUS              RESTARTS   AGE
mongorc-zxjwf                          1/1     Running             0          6s
springappdeployment-5cfd644db9-qbd5g   0/1     ContainerCreating   0          6s
springappdeployment-5cfd644db9-qg62g   0/1     ContainerCreating   0          6s
ubuntu@ip-172-31-33-243:~$ kubectl get all
NAME                                       READY   STATUS         RESTARTS   AGE
pod/mongorc-zxjwf                          1/1     Running        0          72s
pod/springappdeployment-5cfd644db9-qbd5g   0/1     ErrImagePull   0          72s
pod/springappdeployment-5cfd644db9-qg62g   0/1     ErrImagePull   0          72s

NAME                            DESIRED   CURRENT   READY   AGE
replicationcontroller/mongorc   1         1         1       72s

NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service/kubernetes     ClusterIP   10.96.0.1        <none>        443/TCP        5m58s
service/mongo          ClusterIP   10.111.150.154   <none>        27017/TCP      72s
service/springappsvc   NodePort    10.106.65.75     <none>        80:30694/TCP   72s

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/springappdeployment   0/2     2            0           72s

NAME                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/springappdeployment-5cfd644db9   2         2         0       72s


*Above we can see the mongorc-zxjwf data base pod got created. if we want see mode details about pods. 












