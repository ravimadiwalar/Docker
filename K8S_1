Kubernates or K8s it is called and its a replacement of Docker Swarm. K8s will manage the containers. 
k8s is widely used one. why bcoz a) Open source b) Huge community Support c) Brand 
@ K8s is an orchestration engine and open source plantform for managing containerized appliacation. 
@ The container orchestration responsibilities are container deployment, scaling and Descaling of containers and container load balancing. 
@ it was built by google and it is running on Go/Golang language. then donated to CNCF(clound native computing foundation) in 2014.
@ K8s v1.0 was released on July 21 2015. 

Kubernetes Features:
1) Automated Scheduling: K8s provides advanced scheduler to launch container on cluster nodes based on their resource requirements and other constraints, while not sacrificing  availability.
2) Self Healing capabilities: k8s allows  to replace and reschedules conytainer when nodes die. it also kills container don't respond to user-defined health check and doesn't advertise
them to clients until they are ready to serve. if the container goes dowm it will recreate ans reschedule it. 
3) Automated rollouts and rollbacks:  K8s rollout changes to the appliacation or its configuration while monitoring application helath to ensure it doesn't kill our all instances
at the time. if something goes wrong , with kubernetes you can rollback the changes. it means we can roll back to our previous version of the application. 
4) Scaling and load balanacing: k8s can scale up and sclae down the application as per the requirements with a simple commands, using a UI or automatically based on CPU usage. 
5)Service discovery and Load balancing: in k8s will schedule pods and pods will have containers. We no need to worry about networking and communications. bcoz our application will be
running in diff diff nodes. K8s will assign IP to containers and a single DNS name for a set of containers.   that can load-balance the tracffic inside the cluster.
Containers get their own IP  so you can put a set of containers behind a single DNS name for load balancing. 

6)   Storage Orchestration: In k8s also we have concept like volume strage for database. here we can use local/external driver to store the database and we can use EBS, EFS, S3 to stoare 
our database to recreate the conatiner. 

kubernetes Architecture:
-------------------------
K8s implements a cluster(group of servers) background , everything works from inside a Kubernetes Cluster. This cluster is hosted by one node acting as the "master" of the cluster. and the other nodes
as'nodes' which do the actual 'containerization'. 

we have diff conatinerization softwares: Docker, conatier-d, rocket(rkt) and coreOS.  

conatiner orchestration softwares: Docker swarm, Kubernetes and Open shift.
open shift is implemented on top of kubernetes. but it has some addtional security features from Redhat products. its Enterprise(not an open source). 

Kubernetes can manage all type of containerizations. 

* in k8s cluster each and every node(machine)should have container runtime software. this container runtime can be either docker or any other containerization software. 
*In master m/c we have some components after settig up the cluster. a) API Server b) Scheduler c) Control manager d) ETCD . These are called as "control plane". 
* In other m/c are worker m/c's.  they have the components like a)kubelet b) kubeproxy --> yhese are work/slave nodes.

a)API Server: Here we will do all adimisrational functions. API(application programming interface). its a front end of the kubernetes control plane. communication center for developer, systemadmin and other 
kubernetes componetes. if we want do any activity in the cluster i mean deploy some application, update or delete some application etc work will contact Master. within the master 
API Server component will do all activity. 

How can we interact with API server?
--> There are two components we can connect with API server. CLI(command line interface)-kubectl  and GUI(Graphical user interface)- here we can set up a dashboard to connect with API.

Once we start working in CLI to execute any commands the request goes to API server and API server will process that request that information will persist in the ETCD. 

==>ETCD: is key value data store. kind of database. it will have cluster state/info. it has hw many pods we have, node info, deployment info etc. 
==> Schedulers: it will schedule the unassigned pods on the nodes (m/c). it also talks to ETCD to check on unscheduled pods.
                if the node has lot of pods and there is no enough CPU and memory. in that case the schduler will scedue the pods on the other node. 


@ K8s will not create new node if one node goes down. it doesn't manage the nodes. K8s is just a containerization orchestaration software. 

1) Kubelet: The scheduler will schedule the pods with the help of Kubelet. Its a node componenet and its a kind of an agent software for control plane. it runs on each and every node.
the master m/c talk to kubelet to amanage the pods.   

==> Control manager: here we can manay control manager EX: Replication controlmanager, Replica set controlmanager,node controlmanager etc. This control manager controls lot of 
process in the cluster. out of 3 one node goes down the Replication controlmanager or Replica set controlmanager will do desired state reconolation. it will interact with kubelet and 
see hiw many pods are running and manage. if node goes down the node control manager will control/take some actions.

2)Kubeproxy: Its network proxy. it anables the k8s service abstraction by maintaining network rules on the host and performing connection forwarding. it will maintain newtwok proxy 
on nodes. These network rules allow network communication to your pods from inside or outside the cluster. it will do load balancing withing the cluster. 

If we want to access the application from the outside(end user). the request will first goes to Kubeproxy and it will rediret that to requsted pod. we can see these kubelet and 
kubeproxy in matser node also. 


Installation of K8s:
====================
These are penty of ways to install the K8s. but primarily there rae 2 type of k8s clusters 
1)Self managed K8s clusters: we have to manage the cluster. we have some siftwares like Minikube, Kubeadm,kubespray ways to set up the k8s.
will apply this cluster when our client is not ata all ready to host any servoices in clouds and he wants to set up everything in his own data center (on premise infrastructure). 

2) managed k8s cluster (PAAS-Platform as a service): we have 
EKS-Elastic K8s service--> AWS cloud
AKS- Azure k8s service --> Azure cloud
GKE -Google k8s engine --> google cloud
IKE -IBM k8s engine --> IBM cloud  

Here the cloud provider will manage everuything if someting goes wrong. we can use/integrate with other cloud services like loadbalancer, cloud storage,IAM etc.. 
if any worker goes down it will set up another worker.
*in cloud also we can set up a self managed cluster usning cloud features but if anything goes wrong we have to manage. 


==> Minikube: its single node K8s cluster. it means here we can see only one server and that will work as both master and worker/slave. 
==>kebeadm: using this software we can set up multinode selfmanaged k8s clusters. we are installing using selfmanaged cloud based cluster. 

Control plane nodes:
======================
Protocol    Derections     port range     purpose                     Usedby 
TCP          Inbound        6443*         K8s API server               All
TCP          Inbound        2739-2380     ETCD server client API       Kube API server, ETCD 
TCP          Inbound        10250         Kubelet API                  Self, Control plane
TCP          Inbound        10251         kube-Scheduler               self
TCP          Inbound        10252         Kube-control manager         self

Work nodes:
Protocol    Derections     port range     purpose           Usedby
TCP          Inbound        10250         Kubelet API       Self, Control plane


*Why we need Kube proxy in master? 
Suppose we have pods in master node and i want access from the master itself. that time outside user cam also access it.

kubelet: It will manage all control plane. control plane itself running as a pod. kubelet will maintain that. 


@ master node- Needs t2.medium and 2 core cpu and 4GB RAM
@ Worker node- Need t2.micro

So create one EC2 instace with t2. medium and select Ubuntu and open all traffic and set a range 172.31.0.0/16. bcoz all ports open but will be accessible only in that vpc range.
in same VPC i am creating my matsers and workers to communicate with eac other. 

similarly craete 2 more mc's with t2. micro. with same Ubuntu and all trafiic and that same vpc range. 

In real time we host these servers in private subnets. bcoz of security. suppose if we are hosting in private subnet will i able to install required softwares from the internet
(docker, kebeadm, kebelet). NO.. so that time we can use NAT gate if we have in on premise. if we dont have NAT in on premise (company) we need to downlaod required softwares 
as a zip.tar, rpm, apt etc file  wherever you have an access to internet and from that server you can copy to the private server and install the required software. 

We can see the installation of K8s in youtube. 


====COMMAON FOR MASTER AND SLAVE START=======
some softwares are common in both matser and slave. we have to install them one by one.

#First login as a root user 
sudo su -

#Update package manage
apt-get update -y 

#Install and enable docker
apt install docker.io -y
usermod -aG docker ubuntu
systemctl restart  docker
systemctl enable docker.service

#Turnoff the swap memory/space: as per k8s documenatation we have disble swap memeory. 
swapoff -a
sed -i '/ swap / s/^\(.*\)$\1/g' /etc/fstab 

# Install  required packages  and apt keys: 

apt-get install -y apt-transport-https curl

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat <<EOF >| tee /etc/apt/sources.lists.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

apt-get update -y

# Install kubeadm, kubelet and kubectl
apt-get update -y kubeadm kubelet kubectl  --> This is for master node only bcoz we need kubectl in matser node only. if required also no need to install in the mayster also. 
o can take seperate mc. here i can install only CLI. once execute this kubectl command it will talk to API server directly. 
Here kubeconfig file will have API server info. IP adress, which port it is running. whenever we execute kubectl command in this mc. it will use kubeconfig file and request goes to API server.
     -----------

apt-get install -y kubeadm kubelet --> for worker nodes/mc's  

#Enable and start the kubelet service. 
systemctl daemon-reload
systemctl start kubelet
systemctl enable kubelet.service 

Now all required softwares have been installed. whatever mc we want to use that as a matser mc, execute below commands

======In Master Node Start=====

Sudo su -

#Initialize K8s  matser by  executing below command. this will setup control plane softwares in master mc. in the background it will download/pull the imges of all control 
plane components to create the pod. 

kubeadm init


Now we initialized the control plane . scroll down at the end we can see 

'kubeadm join 172.31.43.204:6443........ '  ==> 172.31.43.204- master mc IP address and 6443- API server port

it measn using we can conncet with other worker mc's (execute them in worker mc). they can interract with each other once we done this. 

on top of this console display we can see "to start using cluster you need to run fallowing as regular user". here we are copying kubeconfig file and creating kubectl.
but kubectl will not be matser/worker mc. once the installation done it will talk to API server. 

#exit as root user and execute as a normal ubuntu user.
exit

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

To check the kubectl version==> kubectl version
This will work once we install the kubeconfig file only. 

ubuntu@ip-172-31-188-19:~kubectl get nodes
NAME             STATUS          ROLES                   AGE     VERSION
172-31-188-19     Not Ready      control plane, master    5m      v1.21.2

above we can see the kubectl is not ready yet. bcoz we need pod network. 

POD Networking: 
--> Kubernetes CNI--> container Networking Interface.   interface is nothing but standards. K8s will defien some standards for networking. and we have diff impplementataions

calico network
flannel network
weave network 
etc

ubuntu@ip-172-31-188-19:~kubectl get pods -n kube-system
NAME                                       READY   STATUS    RESTARTS   AGE
coredns-74ff55c5b-9jmdj                    0/1     Pending   0          112s
coredns-74ff55c5b-j9ktx                    0/1     Pending   0          112s
etcd-ip-172-31-33-243                      1/1     Running   0          117s
kube-apiserver-ip-172-31-33-243            1/1     Running   0          117s
kube-controller-manager-ip-172-31-33-243   1/1     Running   0          117s
kube-proxy-zfxrk                           1/1     Running   0          113s
kube-scheduler-ip-172-31-33-243            1/1     Running   0          117s


we can see corednc. Within the k8s there is a DNS (domain name service). one applicataion want to talk to another will use DNS.   
but these dns are in pending status bcoz required network is not there. now apply weave network. 

ubuntu@ip-172-31-188-19:~kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
.
.
.
now it has craeted weave network. 

ubuntu@ip-172-31-188-19:~kubectl get pods -n kube-system
NAME                                       READY   STATUS            RESTARTS   AGE
coredns-74ff55c5b-9jmdj                    0/1     Pending           0          2m34s
coredns-74ff55c5b-j9ktx                    0/1     Pending           0          2m34s
etcd-ip-172-31-33-243                      1/1     Running           0          2m39s
kube-apiserver-ip-172-31-33-243            1/1     Running           0          2m39s
kube-controller-manager-ip-172-31-33-243   1/1     Running           0          2m39s
kube-proxy-zfxrk                           1/1     Running           0          2m35s
kube-scheduler-ip-172-31-33-243            1/1     Running           0          2m39s
weave-net-bkldg                            0/2     PodInitializing   0          11s

above we can see the dns is in running status and we can see weave network also. 

ubuntu@ip-172-31-188-19:~kubectl get nodes
NAME             STATUS          ROLES                   AGE     VERSION
172-31-188-19     Ready      control plane, master    5m      v1.21.2

now my master mc is also ready. now will connect this with worker mc's. using tokens. to find the tolen use below and copy that execute that token in other 2 mc's. 
now my cluster is ready.

ubuntu@ip-172-31-188-19:kubeadm token create --print-join-command


to check whether cluster is ready or not. execute below command in master mc.

ubuntu@ip-172-31-188-19:~ kubectl get nodes 

here we can see other mc IP adress also and see whether they rae ready or not. 


======step by step======

sudo su -
apt update -y
apt install docker.io -y

#Install and enable docker
apt install docker.io -y
usermod -aG docker ubuntu
systemctl restart  docker
systemctl enable docker.service

#Turnoff the swap memory/space: as per k8s documenatation we have disble swap memeory. 
swapoff -a
sed -i '/ swap / s/^\(.*\)$\1/g' /etc/fstab 

# Install  required packages  and apt keys:

sudo apt-get install -y apt-transport-https ca-certificates curl
curl -fsSL https://dl.k8s.io/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

apt update -y

# Install kubeadm, kubelet and kubectl
sudo apt install kubeadm=1.20.0-00 kubectl=1.20.0-00 kubelet=1.20.0-00 -y

systemctl daemon-reload
systemctl start kubelet
systemctl enable kubelet.service 

kubeadm init

#exit as root user and execute as a normal ubuntu user.
exit

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

kubectl get nodes

#weave network
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml















